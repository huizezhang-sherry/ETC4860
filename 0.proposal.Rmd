---
title: "Exploration of Facial Expression in Legal Proceedings"
author: "Huize Zhang"
date: "22/04/2019"
output: 
  pdf_document:
    toc: true
    toc_depth: 2
bibliography: 0.reference.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

\newpage

# Background 

In @judicalguid, A judge is expected to "maintain a standard of behaviour in court that ... does not diminish the confidence of
litigants, ... , in the ability, the integrity, the impartiality and the independence of the judge" and this is achieved through certain judicial demeanour [@tutton2018judicial] and [@goffman1956nature]. However, from a behaviour perspective, some facial and vocal inflections are often unbeknown to the speakers [@ekman1991invited] and thus many scholars are studying the court outcome through the language and words used by the judges in the court [@Shullman2004illusion] and vocal and facial characteristics of the Justices [@chen2018justice]. 

Most of the paper above are conducted using the U.S. Supreme Court Database and less studies have conducted using Australia High Court data. Tutton [-@tutton2018judicial] has used an ethnographic approach to study the transcript and audio visual recordings in the High Court of Australia but the study is conducted in an observational manner via matching the Justices' body movement and appearance with the transcript.

It is thus not difficult to notice that a more accurate approach could be employed to understand the emotion of the Justices in the court. From the other end, the advancement in computer vision algorithm and software development make it possible for researchers to apply the facial recognition technology to a wide range of studies. Statistical analysis for the Justices' facial images has yet to be used by researchers to understand their decision making process. 

# Literature Review

## Legal study from a behaviour perspective 

There's existing literature to understand the emotion of the Justices from a linguistic perspective and suggest some factors that could be useful to indicate the justices' vote and thus the court outcome. These factors include the use of pleasant and unpleasant language by @black2011emotions, the frequency and content of Justices' questions by @Shullman2004illusion and @johnson2009inquiring. A statistical method is used by @epstein2010inferring to include a regression analysis to the number of questions asked by the Justices to infer the winning party in the court. 

Other scholars including [@chen2016perceived; @chen2017covering and @schubert1992observing] have studied the emotion of the Justices from vocal characteristics and suggesting that these vocal characteristics especially the perceived masculinity is strongly correlation with the court outcomes . @dietrich2019emotional uses a multilevel logistic model with random effect to suggest subconscious vocal inflections contains information that are not available from textual information. 

Chen [-@chen2018justice] employed both vocal and facial characteristics to predict the court votes using the Supreme Court data from 1946-2014. The audio clips is first preprocessed to get the Mel-frequency  Cepstral  Coefficients (MFCC) and then applied to a random forest model while the image features are extracted using Histogram of Oriented Gradients (HOG). However, this approach on image feature extraction is a general method for image analysis and more specific facial recognition software is readily available to  extract human facial features. We have yet to see these facial recognition technology being applied to the legal study. 


## Facial Recognition

An Anatomical analysis of facial action was conducted in 1976 by @ekman1976measuring and there comes the Facial Action Code(FAC) @ekman1978, which has been further revised by @ekman2002facial This decomposition of facial muscles is widely used in scientific research, animation (https://www.paulekman.com/facial-action-coding-system/). An example is its application in competitive sports, specifically tennis. @kovalchik2018going find that the emotion of professional tennis players will have an impact on the their performance and the Facial Action Coding System(FACS) is modified to sport-relevant emotions to better suits the context. 

From the computation side, a series of emotion recognition challenges then pop up with an aim to solve the issues in the algorithm for detecting facial emotions in the real-world audio-video based images (Emotion Recognition In The Wild Challenge and Workshop (EmotiW) 2013: @dhall2013emotion and @kahou2013combining; Audio/Visual Emotion Challenge: @schuller2012avec and @schuller2011avec). 

Facial recognition software are also coming out from those big names i.e. DeepFace [@schroff2015facenet] from Facebook and FaceNet [@taigman2014deepface] from Google. OpenFace [@baltrusaitis2018openface] is the first of its kind open-sourced face recognition software that provides facial expression detection including facial landmarking, head pose estimation, eye gaze tracking and facial action unit detection. Along with its previous version (@baltruvsaitis2016openface), the OpenFace toolkit has been used in different social researches including depression classification(@yang2016decision and @nasir2016multimodal).  


# Motivation and Aim 

## Motivation

The motivation of my research starts from Stephanie's [-@kovalchik2018going] paper, where she applies the OpenFace Technology to understand the emotion status of tennis players. This study provides a new perspective to understand the facial emotion of human being and thus I would be interested to see if this technique could also be applied to the courtroom, where the emotion status of the Justices is a key factor for understanding their votes. 

## Aim

The aim of my study is to explore the possibility of using facial recognition technology to understand Justices decision. Notice that due to the fact that this study is the first of its kind of applying facial image analysis to study legal decision, a lot of pre-work of understanding the variables created by the software has yet to be done. This will be the focus of this research project since a good forecasting model can only be produced after the data is understood well. 


# Data 

## Source Data
Unlike most of the research, the source data I get are AV recordings publicly available from the High Court of Australia (http://www.hcourt.gov.au/cases/recent-av-recordings). Multiple procedures and a quite bit of time is spent to get the numerical dataset suitable for statistical analysis.

## Data Extracting

Due to the High Court restriction, directly download or scraping is not possible and thus we use `youtube-dl` to do it. Second, frames need to be extracted from videos and this is done via `ffmpeg`. `Taipan` is then used to find the x-y coordinate of the location of the judges in each frame and `ImageMagick` is finally used to perform batch processing of cropping the face of each judge from each frame that is taken from each videos. The resulting sequence of cropped images for each judge and each case are then sent to `OpenFace` to produce the variables for facial landmarking, head pose, eye gaze and facial action unit. This step is performed via the docker platform and the resulting docker file is available for re-productivity. The resulting outputs from OpenFace are separate csv files for each frame, each judges and each cases and some file processing is done in R to combine all the separate csv files into a final dataframe with appropriate index of frame_id, judge_id and video_id.

Notice that OpenFace requires the face to have at least 25 pixel to detect while publicly available videos from the High Court of Australia is only at 720p resolution. This makes OpenFace not being able to detect the faces in videos where 7 judges are presented since the pixels for each judge's face is too small. Therefore, the videos being used in this research project includes:

-	Republic of Nauru v. WET040 (Nauru_a) 
- TTY167 v. Republic of Nauru (Nauru_b)
- Rinehart & Anor v. Hancock Prospecting Pty Ltd & Ors on 13 Nov 18 (Rinehart_a)
- Rinehart & Anor v. Hancock Prospecting Pty Ltd & Ors on 14 Nov 18 (Rinehart_b)
- Parkes Shire Council v. South West Helicopters Pty Limited (Parkes)
- McKell v. The Queen (McKell)
- OKS v. The State of Western Australia (OKS)

If we are able to get videos with better quality, there's no technical problem for OpenFace to detect faces in those videos. 

# Analytics 

## Missing Data Treatment

## Four different types of variables 

## Text Analysis 


## Outcome Variables 


# Plan

\newpage

# Appendix
![Workflow for data extraction](workflow.png)

The workflow for extracting numerical data from the videos can be summarised in Figure 1. 
\newpage
# Reference