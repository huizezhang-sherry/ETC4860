---
chapter: 1
knit: "bookdown::render_book"
---

# Introduction {#ch:intro}

## Background and motivation

The decisions of Justices have always been a source of debate and discussion. Since the realist movement in the United States emerged in the 1930s, many attempts have been made to predict decisions using specific characteristics of the Justices such as gender, political views, and religious backgrounds. More recently, scholars [@Shullman2004illusion; @chen2016justice] have utilised Audio Visual (AV) recordings and transcripts to predict the outcome of cases in the U.S. Supreme Court. @tutton2018judicial have used an ethnographic approach to study the judicial behaviour. The study involves manually observing the audio footage and taking notes when an obvious emotion is observed. Manually observation may lead to subjective evaluations of facial expressions when different individuals are observing the same AV recordings. This motivates us to extend @tutton2018judicial's work and employ facial recognition technology to study the facial expressions of the Justices to obtain objective judgements.
 
## Literature review

The literature summary is divided into two sections: (1) current work in legal studies to understand the behaviour of the Justices and (2) existing facial recognition and emotion tagging technology.  

### Legal study from a behaviour perspective 

There is comprehensive law, economics and political science literature that attempts to predict how the Justices will vote in court cases. Some characteristics of the Justices, for example, gender, political view, religious background has been considered in the literature [@Stuart1962; @Peter1984; @Combining1987; @Steffensmeier2001; @Kulik2003]. 

More studies depart from static characteristics of Justices and incorporate the language used by the Justices in the court to understand the decision of the Justices. @black2011emotions have studied the use of pleasant and unpleasant language by the Justices. @Shullman2004illusion and @johnson2009inquiring have studied the effect of frequency and content of Justices' questions. @epstein2010inferring has utilised the number of questions asked by the Justices in regression analysis to predict the winning party in a case . 

Recently, legal studies have focused on the usage of emotion and vocal characteristics of the Justices. From a behavioural perspective, Paul Ekman [@ekman1991invited] suggests that speakers are often unaware of their own facial and vocal inflections. In 2016, @chen2016perceived have studied the emotion of the Justices from vocal characteristics and suggest that perceived masculinity is strongly correlated with the court outcomes. @dietrich2019emotional also suggest that subconscious vocal inflections contain information that is not available from text transcripts using multilevel logistic model with random effects. Another study by @chen2018justice have incorporated both vocal and image information into a machine learning model to predict the votes of the Justices, and case outcome, using the U.S. Supreme Court data from 1946-2014. They found that image and audio features have improved the prediction of case outcomes. This demonstrates the potential of incorporating facial information to understand the Justices. 

The literature often considers the U.S. Supreme Court Database and far less studies have been conducted using Australian High Court data. The Guide to Judicial Conduct [@judicalguid]  has presented the following code of conduct:


>It is important for judges to maintain a standard of behaviour in court that is consistent with the status of judicial office and does not diminish the confidence of litigants in particular, and the public in general, in the ability, the integrity, the impartiality and the independence of the judge. 

This highlights the expectation for the Justices to present impartial in the courtroom. @tutton2018judicial has used a novel ethnographic approach to study the judicial demeanour in the High Court of Australia by using transcripts and AV recordings. The study found that Justices present a detached facial demeanour during the court most of the time, but some human display of emotions such as laughter and humour were also captured. However, their approach of manually observing the AV recordings could be biased and lead to subjective results influenced by the individuals observing the videos. An objective approach utilising facial recognition technology is employed in this project to study the expressions of the Justices aiming to produce objective results. 





### Facial recognition

An anatomical study of the decomposition of facial muscles by @ekman1976measuring has led to the development of Facial Action Code (FAC), and the identification of the six universal emotions on human faces. This work has laid a solid foundation for analysing facial expressions. Effective facial recognition software, for example DeepFace [@taigman2014deepface] from Facebook and FaceNet [@schroff2015facenet] from Google, have been developed for face detection in search and social media platforms. OpenFace [@baltrusaitis2018openface] is the first open-sourced face recognition software that provides facial expression detection, including facial landmarking, head pose estimation, eye gaze tracking and facial action unit detection. The OpenFace toolkit has been used in different research areas including depression classification [@yang2016decision], emotion studies [@huber2018emotional] and sports analytics. [@kovalchik2018going].

<!-- ## Research Question  -->

<!-- (placeholder) -->

<!-- - Extract facial expression data of the Justices from videos of High Court of Australia -->

<!-- - Merge with data from text transcript -->

<!-- - Statistically model judges facial expressions -->

<!-- - Provide an **objective** source of data to study the problem -->

<!-- - Do the results agree or disagree with Tutton's findings, that the justices are appearing impartial? -->

<!-- Two questions can be explained by the model:  -->

<!-- - Do the justices' expression differ from case to case?  -->
<!-- - Do the justices' expression differ when different parties are speaking? -->


<!-- The aim of this study is to use facial recognition technology to detect judicial thinking and thus their decisions. There are four specific objectives: -->
<!-- • Read in video streams and convert into a numerical data format. -->
<!-- • Perform data quality checks to investigate video and data quality. -->
<!-- • Exploratory data analysis of the facial expression, transcript variables and outcomes. -->
<!-- • Explore models to predict the appeal outcomes based on facial expression and text analysis. -->



## Cases selected in the project 

Six cases have been analysed in this project and they are chosen to cover a broad range of legal areas. Two cases from **immigration** law were chosen because a series of decisions made by the High Court of Australia related to refugee and immigration status has led the Republic of Nauru to abolish the mechanism that parties could appeal decisions from the Supreme Court of Nauru to the High Court of Australia. 

In Republic of Nauru v WET040 [No. 2] [2018] HCA 60, an Iranian national (respondent) was seeking for asylum protection from the Secretary of the Department of Justice and Border Control (DJBC) and was rejected. Three High Court Justices sat the hearings were Justices Gageler, Nettle and Edelman and the case is referred to as Nauru-a in this project. 

Another case from immigration law is TTY167 v Republic of Nauru [2018] HCA 61, where a Bangladesh citizen (appellant) applied to Nauru's Secretary of the Department of Justice and Border Control for refugee protection. The appellant then appealed to the Tribunal and further appealed to the High Court of Nauru but was rejected. He then appealed to the High Court of Australia and successfully got his refugee status. This case is also heard by Justices Gageler, Nettle and Edelman and it is referred as Nauru-b.

Rinehart v Hancock Prospecting Pty Ltd [2019] HCA 13 is a **commercial** case discussing commercial arbitration. Due to its complexity, the case were held in two hearings named Rinehart-a and Rinehart-b in the project. Chief Justices Kiefel, Justices Gageler, Nettle, Gordon, and Edelman heard the case. A distinct characteristics of this case is that the decision is not a unanimous decision of all the Justices. Justice Edelman took a narrow interpretation of legal issue while the majority of the Justices took a broad interpretation.  

Parkes Shire Council v South West Helicopters Pty Limited [2019] HCA 14 is a **civil** case where the appellant, the Stephenson claimed for psychiatric harm resulting from the death of Mr Stephenson, who was carried and subsequently killed due to the helicopter crash by the Parkes city council (respondent). Chief Justices Kiefel, Justices Bell, Keane, Gordon, and Edelman heard the case and it is referred to as Parkes. 

Another two **criminal** law cases are chosen in the project as the nature of criminal cases are highly different from civil cases. In McKell v The Queen [2019] HCA 5, which is referred to as case McKell, the appellant is a truck driver and was involved in the importation of drug and cash. The trial judge sentenced a 18 years imprisonment and the appellant appealed to the Court of Criminal Appeal and further to the High Court of Australia. The High Court Justices Bell, Gageler, Keane, Gordon, Edelman decided there's a miscarriage of justice and quashed the conviction of the appellant. 

In OKS v Western Australia [2019] HCA 10, the appellant is charged with misconduct with children.  The Court of appeal of the Supreme Court of Western Australia charged the appellant for conviction and the appellant then appealed to the High Court of Australia. Justices Bell, Keane, Nettle, Gordon and Edelman unanimously allowed the appeal and issued a new trial. 

The links to the hearings of the cases can be found in Table A.1 in the Appendix.  

\let\cleardoublepage\clearpage
