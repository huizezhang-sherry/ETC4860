---
chapter: 1
knit: "bookdown::render_book"
---

# Introduction {#ch:intro}

## Background and motivation

The decisions of Justices and Judges have always been a source of debate and discussion. In the past century many attempts have been made to predict decisions using judge specific characteristics such as gender, political views, and religious backgrounds. 
More recently, scholars [@Shullman2004illusion; @chen2018justice] have utilised AV recordings and transcripts, containing language used by the Justices to predict the case outcome of ccases in the U.S. Supreme Court and the High Court of Australia. @tutton2018judicial have used an ethnographic approach to present an observational study of judicial behaviour, based on watching the audio footage. Manually observing the AV recordings may lead to subjective evaluations of facial expression and this motivates us to extend @tutton2018judicial's work and employ facial recognition technology to study the facial expression of the justices to obtain objective judgements @tutton2018judicial.
 
## Literature review

The literature summary is divided into two parts: (1) current work in legal studies to understand the behaviour of the Justices and (2) existing facial recognition and emotion tagging technology.  

### Legal study from a behaviour perspective 

There is comprehensive law, economics and political science literature that attempts to predict how judges will vote in court cases. This literature considers characteristics of the judge and characteristics of the parties in the case; these include gender, political views, religious background of Justices or gender and race of the defendant in criminal cases [@Stuart1962; @Peter1984; @Combining1987; @Susan1988; @Steffensmeier2001; @Kulik2003]. 

Many studies depart from static characteristics of judges to incorporate the language used by the judge in the court to predict the decision of the Justices. 
@black2011emotions have studied the use of pleasant and unpleasant language by the Justices and @Shullman2004illusion and @johnson2009inquiring have studied the effect of frequency and content of Justices' questions. @epstein2010inferring use a regression analysis involving the number of questions asked by the Justices to predict the winning party in a case. 

Recently, legal studies have focused on the usage of emotion and vocal characteristics of the Justices to predict the judge's decisions. @judicalguid present the following code of conduct:

>It is important for judges to maintain a standard of behaviour in court that is consistent with the status of judicial office and does not diminish the confidence of litigants in particular, and the public in general, in the ability, the integrity, the impartiality and the independence of the judge. 

This highlights the value of impartiality expressed by judicial demeanour and discussed by @tutton2018judicial and @goffman1956nature.
Paul Ekman @ekman1991invited takes a behavioural perspective and suggests that speakers are often unaware of their own facial and vocal inflections. @chen2016perceived; @chen2017covering and  @schubert1992observing have studied the emotion of the Justices from vocal characteristics and suggest that perceived masculinity is strongly correlated with the court outcomes. @dietrich2019emotional has used a multilevel logistic model with random effects to suggest that subconscious vocal inflections contain information that is not available from text transcripts.
A sizeable study by @chen2018justice incorporated vocal and image information of the judge into a machine learning model to predict the judge votes, and case outcome, using the U.S. Supreme Court data from 1946-2014. This study showed that image features improved prediction of case outcomes from 64% to 69% and audio features improved prediction of case outcomes from 67% to 69%. This demonstrates the potential of incorporating facial information to understand and predict the decision of the Justices. 

The literature often considers the U.S. Supreme Court Database and far less studies have been conducted using Australian High Court data. @tutton2018judicial has used a novel ethnographic approach to study the judicial demeanour in the High Court of Australia by using transcripts and AV recordings. The study found that Justices present a detached facial demeanour during the court most of the time, but some human display of emotions such as laughter and humour were also captured. Tutton's [-@tutton2018judicial] work has confirmed the potential of using image information to analyse the Justices' behaviour. However this approach which is also taken by Chen [-@chen2018justice], is an ethnographic approach which could biased and lead to subjective results influenced by the people observing the videos. Tutton's [-@tutton2018judicial] study, presents an opportunity to extend image use by utilising facial recognition technology to produce objective results. 



### Facial recognition

An anatomical study of the decomposition of facial muscles by [@ekman1976measuring] led to the development of Facial Action Code (FAC) [@ekman1978] and identification of the six universal emotions on human faces. This work has laid a solid foundation for analysing facial expression and developing facial recognition software [@Kobayashi1992; @huang1997; @lien2000; @Kappoor2003; @Tong2007; @Cohn2009; @Lucey2010]. 

To analyse facial expressions, effective facial recognition capture technology is needed to extract faces from images. Facial recognition software DeepFace [@taigman2014deepface] from Facebook and FaceNet [@schroff2015facenet] from Google have been developed for face detection in search and social media platforms. OpenFace [@baltrusaitis2018openface] is the first open-sourced face recognition software that provides facial expression detection, including facial landmarking, head pose estimation, eye gaze tracking and facial action unit detection. The OpenFace toolkit has been used in different area in research including depression classification [@yang2016decision; @nasir2016multimodal], emotion studies [@Pan2018; @Nasir2016; @Huber2018] and even sports analytics. [@kovalchik2018going].

<!-- ## Research Question  -->

<!-- (placeholder) -->

<!-- - Extract facial expression data of the Justices from videos of High Court of Australia -->

<!-- - Merge with data from text transcript -->

<!-- - Statistically model judges facial expressions -->

<!-- - Provide an **objective** source of data to study the problem -->

<!-- - Do the results agree or disagree with Tutton's findings, that the justices are appearing impartial? -->

<!-- Two questions can be explained by the model:  -->

<!-- - Do the justices' expression differ from case to case?  -->
<!-- - Do the justices' expression differ when different parties are speaking? -->


<!-- The aim of this study is to use facial recognition technology to detect judicial thinking and thus their decisions. There are four specific objectives: -->
<!-- • Read in video streams and convert into a numerical data format. -->
<!-- • Perform data quality checks to investigate video and data quality. -->
<!-- • Exploratory data analysis of the facial expression, transcript variables and outcomes. -->
<!-- • Explore models to predict the appeal outcomes based on facial expression and text analysis. -->




<!-- ## Significance  -->

<!-- (placeholder) -->

<!-- Facial recognition analysis of the videos provides a way to **objectively** and **automatically** assess judicial behaviour. -->
