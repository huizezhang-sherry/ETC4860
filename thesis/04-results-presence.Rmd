---
chapter: 3
knit: "bookdown::render_book"
---


## Filtering action units


The number of action unit to include in the model is a matter of choice. The discussion of this choice is to ensure the model is parsimonious, that is, a model has the smallest number of variables but with greatest explanatory power. Random effect is a way to deal with large number of factor levels of a variable, but in our context, we are only interested in the action units with a certain mean presence and intensity for most of the judges. 

The mean presence and intensity score for each action unit is computed and the action units to include in the model are the ones that appear in the top 10 action unit in both mean presence and intensity rank. This ensures that these action units have both relatively high intensity and presence score. A list of included action units along with their meaning and related emotions are presented in Table \ref{tab:au-included} 

```{r au-included, results = 'asis'}
int <- au_tidy %>% group_by(AU) %>% 
  summarise(int = mean(intensity)) %>% 
  arrange(-int) %>% 
  top_n(10)

AU_included <- au_tidy %>% group_by(AU) %>% 
  summarise(pres = mean(presence)) %>% 
  arrange(-pres) %>% 
  top_n(10) %>% 
  inner_join(int) %>% 
  pull(AU)

au_selected <- au_meaning %>% 
  filter(AU %in% AU_included) %>% 
  separate(Meaning, sep = ": ", 
           into = c("name", "Meaning")) %>% 
  dplyr::select(-name) 

knitLatex::xTab(au_selected, booktabs = TRUE, caption.top = "\\label{tab:au-included} These are the selected action units that will be included in the modelling for intensity and presence.")
  
```


## Modelling result for presence 

### Model comparison

The three models in Equation \ref{eq:judge_au}, \ref{eq:judge_video} and \ref{eq:judge_speaker} have been fitted and ANOVA test is performed to choose the best model. The ANOVA result for comparing Model 1 and 2 is presented in Table \ref{tab:anova-1}. After incorporating the main effect of case and its interaction with judge in Model 2, the degree of freedom is reduced by 61. This has a significant improvement on the model since the p-value (1e-88) is close to zero, indicating the null hypothesis that Model 1 and Model 2 are the same is rejected. 

The ANOVA result between Model 2 and Model 3 is presented in Table \ref{tab:anova-2}. The additional six variables associated with speakers in Model 3 have improved the model at 95% significance level since the p-value less than 0.05, however, at 99% significicance level, this improvement is not significant. Model 2 is chosen as the final model because the interpretation of video-wise effect using Model 2 after post-model analysis provides more interesting findings about the expressions of the Justices than the speaker-wise effect using Model 3. 

```{r}
model_dt <- au_tidy %>%
  ungroup(judge) %>%
  filter(AU %in% AU_included) %>%
  mutate(judge = fct_relevel(judge, c("Edelman", "Keane", "Kiefel",
                                      "Nettle", "Gageler", "Bell")),
         video = fct_relevel(video, c("Nauru-a", "Nauru-b", "Rinehart-a",
                                      "Rinehart-b", "Parkes", "McKell", "OKS")),
         AU = fct_relevel(AU, "AU01"))

binomial_model_1 <- glm(presence ~ judge*AU,
                        family = binomial(link = "logit"),
                        data = model_dt)

binomial_model_2 <- glm(presence ~ judge*video + judge*AU + video*AU,
                        family = binomial(link = "logit"),
                        data = model_dt)

binomial_model_3 <- glm(presence ~ judge*speaker + judge*video +
                          judge*AU + video*AU, 
                        family = binomial(link = "logit"),
                        data = model_dt)
```

```{r anova-1, results='asis'}

anova1 <- tibble(Model = c("Model 1", "Model 2")) %>%
  bind_cols(as.tibble(anova(binomial_model_1, 
                        binomial_model_2, 
                        test = "Chisq"))) %>% 
  mutate(Df = ifelse(!is.na(Df), Df, " "))%>%
  mutate(Deviance = ifelse(!is.na(Deviance),
                        format(Deviance, digits = 2,), " ")) %>%
  mutate(`Pr(>Chi)` = ifelse(!is.na(`Pr(>Chi)`),
                        format(`Pr(>Chi)`, digits = 2,), " ")) 
  
knitLatex::xTab(anova1, booktabs = TRUE, caption.top = "\\label{tab:anova-1}Model comparison using ANOVA for Model 1 and 2. The inclusion of video related variables in Model 2 decreases the degree of freedom by 61 while provides a significant improvement on the model as indicated by the p-value. ")
```

```{r anova-2, results='asis'}

anova2 <- tibble(Model = c("Model 2", "Model 3")) %>%
  bind_cols(as.tibble(anova(binomial_model_2, 
                        binomial_model_3, 
                        test = "Chisq"))) %>% 
  mutate(Df = ifelse(!is.na(Df), Df, " "))%>%
  mutate(Deviance = ifelse(!is.na(Deviance),
                        format(Deviance, digits = 2,), " ")) %>%
  mutate(`Pr(>Chi)` = ifelse(!is.na(`Pr(>Chi)`),
                        format(`Pr(>Chi)`, digits = 2,), " ")) 
  
knitLatex::xTab(anova2, booktabs = TRUE, caption.top = "\\label{tab:anova-2}The model comparison result of Model 2 and Model 3 using ANOVA. The inclusion of six speaker related main and interaction effects contribute to improve the model. However, this is not significant at 99\\% significant level. Model 2 is chosen as the final model because the interpretation of video effect provides more interesting findings about the facial expressions of the Justices. ")
```



<!-- A bit more work on  -->
<!-- 1) how the glm standard error is computed:  -->
<!-- ```{r} -->
<!-- o <- glm(y ~ x, data = dat) -->
<!-- std.er <- sqrt(t(C) %*% vcov(o) %*% C) -->
<!-- # check if it is the same as pred$se.fit -->
<!-- pred <- predict(o, newdata = data.frame(x=1.5), se.fit = TRUE) -->
<!-- ``` -->

<!-- 2) if HC estimator of sigma is needed  -->
<!-- 3) if adjustment is needed for clusteringstandard error:  -->
<!-- http://civil.colorado.edu/~balajir/CVEN6833/lectures/GLM-theory-notes.pdf -->
<!-- http://civil.colorado.edu/~balajir/CVEN6833/lectures/glm-estimation-presentation.pdf -->
<!-- https://stats.stackexchange.com/questions/332077/glm-standard-errors -->


### Residual Diagnostics and post-model analysis 

The residuals of Model 2 are plotted against variable judge and video in Figure \ref{fig:resid-judge} and \ref{fig:resid-video} in the Appendix. There is no obvious pattern shown in the residuals for different Justices or videos, which indicates adequate fit. 

The estimated marginal mean is computed and presented in Table \ref{tab:result-2} in the Appendix due to its length. The `prob` column can be interpreted as after averaging over all the videos and speaking parties, the estimated mean probability for judge Edelman in action unit AU02 is 0.95, with a 95% confidence interval of [0.92, 0.97]. Notice that confidence intervals for a generalised linear model is asymmetric around the estimates because the linear symmetric interval of the mean has been transferred via the inverse of link function to get the confidence interval for the response. 

### The presence of facial expression of the justices by video

The 95% confidence interval after bonferroni adjustment is plotted in Figure \ref{fig:model2-plot}. In general, most of the intervals for the same judge in the same action unit are overlapping with each other on the vertical axis, while there are some non-overlappings highlight the potential inconsistency of the facial expressions of the Justices. 

Justice Edelman and Keane behave consistently throughout all the videos, while they both seem to express significantly less in action unit 5 (upper lid raiser) in the OKS case. Justice Nettle has relatively low expression of action unit 4 (brow lowerer) in case Rinehart-a. Gageler shows a consistently high number of expressions in case OKS for action unit 15 (lip corner depressor) and action unit 20 (lip stretcher). 

Bell presents similar reactions to Gageler, showing a significantly higher proportion of emotions associated with action unit 1 (inner brow raiser), 14 (dimpler), 15 (lip corner depressor) and 20 (lip stretcher) in case OKS. Bell also  exhibits less presence of action unit 07 (lid tightener) and 20 (lip stretcher) in case Parkes. 

```{r model2-plot, fig.cap="The 95\\% confidence interval for estimated mearginal mean for presence after bonferroni adjustment. The x axis represents video and the y axis represents the estimated marginal mean of an action unit being observed. The facet shows the Justices in columns and action units in rows. "}
emmean_obj_2 <- emmeans(binomial_model_2, c("judge", "video", "AU"),
                        type = "response")

int_2 <- confint(emmean_obj_2, by = c("judge", "AU"), adjust = "bonferroni")

int_2 %>% 
  left_join(au_meaning, by = "AU") %>% 
  filter(!is.na(df)) %>% 
  ggplot(aes(x= video, y = prob,  group = judge)) + 
  geom_point(aes(col= video)) + 
  geom_line(alpha = 0.5, lty = "dashed") + 
  geom_errorbar(aes(ymin = asymp.LCL, ymax = asymp.UCL, col= video), 
                width = 0.2) + 
  facet_grid(Meaning ~ judge, scales = "free",
             labeller = label_wrap_gen(width = 5)) + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1), 
        strip.text.y = element_text(angle = 0),
        legend.position = "none") + 
  xlab("video")

```    

## Modelling result for intensity

### The intensity of facial expression of the justices by video

The two part model in equation \ref{eq:two-part1} is estimated for the intensity data. Estimated marginal mean and confidence interval adjustment procedure are performed as modelling presence data. The 95% confidence interval plot is presented in Figure \ref{fig:intensity-video}. This shows that Justices Edelman has significantly stronger expressions of brow lowerer (AU04) in case Nauru-a, Nauru-b and Rinehart-a, but less intensity when expressing lid tightener (AU07) in case OKS. Justice Keane also shows more intense expressions of lid tightener (AU07) in case McKell. 

Action unit 5 (upperlid raiser) and 20 (lip stretcher) are exhibited significantly more intense for Justices Gageler in case OKS. The mean for brow lowerer (AU04) seems to higher than those in other cases for Justices Gageler but this result is not significant. 

For Justice Bell, the intensity of inner brow raiser (AU01), upper lid raiser (AU05), dimpler (AU14) and Lip stretcher (AU20) are also significantly higher in case OKS. 


```{r intensity-data}
model_dt <- au_tidy %>%
  ungroup(judge) %>%
  filter(AU %in% AU_included) %>%
  mutate(judge = fct_relevel(judge, c("Edelman", "Keane", "Kiefel",
                                      "Nettle", "Gageler", "Bell")),
         video = fct_relevel(video, c("Nauru-a", "Nauru-b", "Rinehart-a",
                                      "Rinehart-b", "McKell", "OKS", "Parkes")),
         AU = fct_relevel(AU, "AU01"),
         non_zero = as.factor(ifelse(intensity ==0, 0, 1)))

# model_dt %>% group_by(non_zero) %>%
#   summarize(count = n(), prop = count/nrow(model_dt))
```

```{r intensity-model-1}
m1 <- glm(non_zero ~ judge*video + judge*AU + video*AU,
          data = model_dt, family = binomial(link = "logit"))
m2 <- glm(intensity ~ judge*video + judge*AU + video*AU,
          data = subset(model_dt, non_zero == 1),
          family = Gamma(link = "log"))
```

```{r intensity-video, fig.cap="The 95\\% confidence interval for estimated mearginal mean for presence after bonferroni adjustment. The x axis represents video and the y axis represents the estimated marginal mean of the intensity. The facet shows the Justices in columns and action units in rows. "}

emmean_m2 <-  emmeans(m2, c("judge", "video", "AU"), type = "response")
int_2i <- confint(emmean_m2, by = c("judge", "AU"), adjust = "bonferroni") # the by argument prescribe

int_2i %>%
  left_join(au_meaning, by = "AU") %>%
  filter(!is.na(df)) %>%
  ggplot(aes(x= video,
             y = response,  group = judge)) +
  geom_point(aes(col= video)) +
  geom_line(alpha = 0.5, lty = "dashed") +
  geom_errorbar(aes(ymin = asymp.LCL, ymax = asymp.UCL, col= video),
                width = 0.2) +
  facet_grid(Meaning ~ judge, scales = "free",
             labeller = label_wrap_gen(width = 5)) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1),
        strip.text.y = element_text(angle = 0),
        legend.position = "none") +
  xlab("video")
```

### The expression of the justices by speaker

From the presence and intensity figures which are colored by speakers in Figure \ref{fig:model3-plot} and \ref{fig:intensity-speaker} in the Appendix, we can observe that the video-wise difference between Justices is still preserved when the speaker effects are included in the model. However, the speaker-wise difference is not significant in terms of both presence and intensity for all the Justices. 

\let\cleardoublepage\clearpage
