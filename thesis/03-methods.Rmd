---
chapter: 2
knit: "bookdown::render_book"
---

# Method

## Notation

Let $\mathbf{X}$ be a matrix of predictors, and $\mathbf{Y}$ variable in our case is bivariate matrix of response variables, including a binary indicator of presence/absence and a numeric value measuring intensity, of facial action unit, where 

- $X_1$ indicates `judge` with six categories $i = 1,2, \cdots, 6$

- $X_2$ indicates `video` for each of the seven cases, $j = 1,2, \cdots, 7$

- $X_3$ indicates action unit containing `r length(unique(au_tidy$AU))` possible facial expression.  

- $X_4$ indicates `speaker`, either the appellant or respondent, $l=1,2$

- $X_5$ indicates `frame` corresponding to time, $t = 1,2, \cdots, T_j$

Note that $t$ could be considered a time variable, but because images are taken at 1 minute intervals, temporal dependence is unlikely to exist. Rather this should be considered an independent observation. 

A full, main effects model for the data might be expressed as:

$$Y_{ijkl} = \mu + \alpha_i + \beta_j + \gamma_k + \delta_l + \varepsilon_{ijkl}$$ 

\noindent and we would be interested in interactions between judge, case, action unit and speaker. An alternative model structure, is to treat each action unit individually, and fit separate models. 

Also, let $P_{jitkl}$ represent the response variable presence, and $I_{jitkl}$ represent the second response variable intensity. This notation will be helpful for defining the plots and models explained in this section.

## Modelling

### Model 1: Action unit

The first model I use is a generalised linear model with binomial link to understand the presence of the action units. The variables used include the judge, action units and their interactions. The use of interaction terms allow for the effect of judge to be differed at different action unit level. The model can be written down as Equation \ref{eq:judge_au}. 

\begin{equation}\label{eq:judge_au}
P_{ik} = \mu + \alpha_i + \gamma_k + (\alpha\gamma)_{ik}
\end{equation}

Based on this model structure, I can understand whether different factor level of action units have different effects on the same judges via ANOVA test. 

<!-- Analysis of Variance (ANOVA) test [reference] allows us to see if collectively, different factor levels of judge and action unit are the same or different ($\alpha_1 = \alpha_2 = \cdots = \alpha_6$). However, it doesn't explain which factor level causes this difference and thus we need multiple comparison.  -->


### Model 2: Video

The second model as shown in Equation \ref{eq:judge_video} is estimated to understand the interaction effect between judge and video while taking into account the main effect of judge, video and action unit and other pair wise interactions. 

\begin{equation}\label{eq:judge_video}
P_{ijk} = \mu + \alpha_i + \beta_j +\gamma_k + (\alpha\beta)_{ij} + (\alpha\gamma)_{ik} + (\beta\gamma)_{jk}
\end{equation}

Building upon the previous model, we incorporate the effect of videos in this model. There are three main effects of judge, video and action unit in the model.  We also incorporate the interaction term between judge and video, which allows the effect of judge to change at each video level. The interaction term for video and action unit is also added because this allows different videos to have different present score for each different action unit. 

### Model 3: Speaker

The third model as shown in Equation \ref{eq:judge_speaker} is estimated to understand the interaction effect between judge and speaking party. 

\begin{equation}\label{eq:judge_speaker}
P_{ijkl} = \mu + \alpha_i + \beta_j +\gamma_k + \delta_l + (\alpha\beta)_{ij} + (\alpha\gamma)_{ik} + (\beta\gamma)_{jk} + (\alpha\delta)_{il}
\end{equation}


In our context, the inclusion of more interactions will be helpful to explain the Presence score. However, the number of interactions is bounded by the degree of freedom we have. We will need to select the most important interactions to include while leave the less important ones. 

### ANOVA 

<!-- - a very technical explanation the computation of ANOVA: http://users.stat.umn.edu/~helwig/notes/aov2-Notes.pdf -->

<!-- - ANOVA is an F test telling us if the model without a term is significantly different from another.  -->

<!-- - there are three types of anova used for calculating the sum of square for covariate with interactions. Type I takes a sequential approach and the order of factor to test will potentially affect the result. Type II ANOVA tests the main effect of a covariate after controlling for other covariate. This approach is recommended if the interactions are not significant. Type III ANOVA tests the main effect of a covariate after controlling for other covariate and the interactions. It is better than Type II if the interactions are significant.  -->

<!-- - there are different packages in R does anova test: `anova()` and `drop1()` from base R and`Anova()` from `car` package. `anova()` from base R provide the type I test and `drop1()` is for type II test, while `Anova()`from `car` package allows for both type II and III via a `type` argument. `aov` from `states` package is specific for balanced data.  -->

<!-- - in our study, all the three give the same answer and suggest all the variables are significant.  -->

<!-- - `singular.ok = TRUE` need to specify for `Anova()` when `type = "III"` because the interaction terms will cause perfect collinearity. Therefore, 2 df is taken from `judge`. -->

<!-- - However, in out context where the variables are multi-level factors, it does tell us which level or levels cause the difference. therefore, we need multiple comparison to compare each factor level.  -->


## Post-Model Analysis

### Estimated Marginal Mean (EMM)

Estimated Marginal Mean (Sometimes called least square mean) is the prediction from a linear model over a defined reference grid. 


<!-- - see the calculation of emm when presented with unbalanced data: weight is for averaging over a continuous variable, which is irrelevant for our study -> don't have to adjust weight -->

<!-- - typically the tests and confidence intervals are asymptotic. Thus the df column for tabular results will be Inf.[have a look at the confidence interval for glm: https://cran.r-project.org/web/packages/emmeans/vignettes/models.html] -->


### Multiple Comparisons 

<!-- - a very important paper on `multcomp` package: @hothorn2008simultaneous -->
<!-- other packages do the same thing: `linearHypothesis` -->



<!-- [may be go to discussion???]Rather than doing *one* hypothesis testing on if two statistics are (significantly) different or not, we are interested comparing if multiple statistics under the same family are the same or different. Under the first model, the family is each action unit, that is, we want to compare that for the same judge, whether the percentage of appearance of action units are the same or different.  P-value and confidence interval are both tools for quantifying uncertainty of estimation. However, in the context of multiple comparison, adjustment need to be made for thesis statistics to be meaningful.  -->

<!-- Testing significance based on the usage of p-value has been long criticised for its interpretation. Researchers can erroneously conclude significance becuase of p-value being less than 0.05 without discussing the false positive/negative rate. [add reference: (Yates, 1951; Savage, 1957; Rozeboom, 1960; Gardner and Altman, 1986; Simon, 1986; Bulpitt, 1987)]. The correct interpretation for a p-value being less than 0.05 is that the estimated quantity are significant subject to 5% of false positive rate. This indicates, -->
<!-- if 100 tests are conducted simultaneously, we would expect around 5 variables being significant purely due to randomness.  -->

<!-- This is especially a problem in our context when comparing the intensity score for all the available (judge, video, AU, speaker) pairs.  The judges are expected to be impartial while we believe they may have some facial expressions during the hearing because they could be unbeknown to the speakers. It would be an concern if we don't control the false positive rate, which occurs when the judges didn't expression a facial expression but we claim they do.  -->




Bonferroni adjustment [@rupert2012simultaneous] is a method to reduce the false positive rate at the cost of relatively cheap false negative rate. In the context of large scale ($N$) hypothesis tests, rather than concluding significance at $\alpha$% for each individual test, Bonferroni method adjusts the critical value to $\alpha/N$% for each single test. In this sense, Bonferroni adjustment controls the family-wise error rate at level $\alpha$. 



<!-- In both methods, the critical value of 0.05 is adjusted based on the number of simultaneous test and an assumption of independent test is made. <!-- For example, say there are 100 mean need to be compared, for us to conclude a particular mean is significant, we need a p-value to be less than the adjusted critical value: `0.05/100` (0.05/100) - maybe we don't need this for example.  
[need some reference on both adjustment: http://www.biostathandbook.com/multiplecomparisons.html]  -->

<!-- A better method to present the same result is through reporting the confidence interval and then comparing if intervals overlap with each other [some reference on the preference of confidence interval for doing comparison].  -->


