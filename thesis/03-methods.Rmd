---
chapter: 2
knit: "bookdown::render_book"
---

# Methodology{#Ch:method}

## Notation

Let $\mathbf{X}$ be a matrix of predictors, and $\mathbf{Y}$ variable is a bivariate matrix of response variables, including a binary indicator of presence/absence and a numeric value measuring intensity, of facial action unit, where 

- $X_1$ indicates `judge` with six categories $i = 1,2, \cdots, 6$
- $X_2$ indicates `video` for each of the seven cases, $j = 1,2, \cdots, 7$
- $X_3$ indicates action unit containing 18 possible facial expression. 
- $X_4$ indicates `speaker`, either the appellant or respondent, $l=1,2$
- $X_5$ indicates `frame` corresponding to time, $t = 1,2, \cdots, T_j$

Note that $t$ could be considered a time variable, but because images are taken at 1 minute intervals, temporal dependence is unlikely to exist. Rather this should be considered an independent observation. 

A full, main effects model for the data might be expressed as:

$$Y_{ijklt} = \mu + \alpha_i + \beta_j + \gamma_k + \delta_l + \varepsilon_{ijklt}$$ 

\noindent Also, let $P_{ijklt}$ represent the response variable presence, and $I_{ijklt}$ represent the response variable intensity. This notation will be helpful for defining the plots and models explained in this section.

## Modelling presence

### Model structure

The presence score is a binary variable that is one when a particular action unit is observed and zero if not. A logistic model is able to capture this binary feature of the presence score and we implement it using the `glm()` function from base R. The link function of a matter of choice in the generalised linear model and the logit link is chosen because it is the canonical link of the binomial family. An alternative link could be a probit link but theoretically, these two links give very similar result in terms of prediction [@faraway2016extending]. The structure of the model is written in Equation \ref{eq:logit-structure} with the first equation linking the mean of the presence to the linear prediction and the second equation specifying the linkage between $\eta$ to predictors. The next section will specify three different function forms for the linear predictor. 

\begin{align}
\mu &= \frac{e^{\eta}}{1 + e^{\eta}} \\
\eta &= f(\alpha_i\text{,}\beta_j\text{,}\gamma_k\text{,}\delta_l) (\#eq:logit-structure)
\end{align}

### Model 1: Action unit

The first linear predictor is presented in Equation \ref{eq:judge_au}. It includes the main effect of judge, action unit and also their interaction. Interaction terms are included to capture the judge-wise differences for different action units and it is necessary because we suspect different judges could have different average presence scores for different action units. 

\begin{align}\label{eq:judge_au}
\eta_{ik} &= \mu + \alpha_i + \gamma_k + (\alpha\gamma)_{ik} + \varepsilon_{ik}
\end{align}

### Model 2: Video

Build upon the first model, the second model adds the video related main effect and interactions, as shown in Equation \ref{eq:judge_video}. The interactions allow both variable judge and action unit to differ in different videos. This model structure is useful to answer the research questions *Whether the judges are behaving same or different across videos*? 

\begin{align}\label{eq:judge_video}
\eta_{ijk} &= \mu + \alpha_i + \beta_j +\gamma_k + (\alpha\beta)_{ij} + (\alpha\gamma)_{ik} + (\beta\gamma)_{jk} + \varepsilon_{ijk}
\end{align}

\noindent 

### Model 3: Speaker

Build upon the second model, the third model is aimed to capture the speaker-wise effect by including the judge and speaker interaction as in Equation \ref{eq:judge_speaker}. This model is built attempting to answer the question:  *Do the expressions of the judges change when different parties are speaking*? 

\begin{align}\label{eq:judge_speaker}
\eta_{ijkl} &= \mu + \alpha_i + \beta_j +\gamma_k + \delta_l + (\alpha\beta)_{ij} + (\alpha\gamma)_{ik} + (\beta\gamma)_{jk} + (\alpha\delta)_{il} + \varepsilon_{ijkl}
\end{align}

### Model comparison

The analysis of variance (ANOVA) [@faraway2016extending; @gelman2006data] is a statistical method for model comparison. We use the base R `anova()`  function to compare the three models via chi-square tests.


## Modelling intensity 

The intensity score is a continuous variable, with zero indicating an action unit is not present to a maximum intensity of five and a histogram of the intensity is plotted in Figure \ref{fig:intensity}.  The data has a high proportion of zeros and the non-zero values are highly skewed.  This type of data is the so-called semi-continuous data [@twopart2010]. and can be modelled in the econometrics literature by a two part model [@cragg1971some]. In the two part model, the data is viewed to be generated sequentially, which has a mixed distribution of 

- a logistic model of if Y = 0 or not, and 
- a specific model for the conditional distribution of $y \mid y > 0$. 

```{r intensity, fig.cap = "From the histogram of the intensity score, the data is highly skewed with an excessive amount of zeros. The two part model is about to accommodate the excessive zeros via the logistic model and gamma regression is about to capture the skewness in the data."}
au_tidy %>% ggplot(aes(x = intensity)) + geom_histogram()

```

The choice of model between two part model and sample selection model is always discussed in the literature. Monte-Carlo simulation studies by different researchers [@leung1996choice; @duan1984choosing; @manning1987monte] show different results on whether these two classes of model are answering the same or distinct inferential questions. The reason for us to choose two part model rather than sample selection model is because unobservability is not a problem in our case. In another word, if an action unit is not present for an observation, it doesn't make sense to talk about "intensity score if the action unit was present". Tobit model is not appropriate because the data can't be viewed as normally distributed with negative value censored as zero (meaningless to say negative intensity value). Zero inflated model is not used because it considers two source of zeros in the data while there is no zeros being generated from the conditional distribution defined below. 

The two part model has a general structure as in Equation \ref{eq:two-part-general}. 

\begin{align}\label{eq:two-part-general}
\mu^1 &= \frac{e^{\eta}}{1 + e^{\eta}} \\
\eta &= f(\alpha_i, \beta_j, \gamma_k, \delta_l) \\
\mu^2 &= \log(I) \\
E(I \mid I > 0) &= f(\alpha_i, \beta_j, \gamma_k, \delta_l)
\end{align}

\noindent where $\mu^1$ is the mean of the intensity score and $\mu^2$ is the mean for intensity given intensity > 0. The first two equations capture the logit link and its linear predictor in the logistic regression. The third and fourth equation specify the functional form of the conditional distribution. 

The functional form of the conditional distribution need to be able to capture the highly skewed nature of the non-zero observations. A convention approach is to assume the conditional distribution is a lognormal distribution [@manning1981two; @diehr1999methods]. More recent literature proposes the use of gamma or generalised gamma regression model [@twopart2010]. Gamma regression is chosen to because it could also capture the right skewness and it can be easily implemented via the `glm()` function. The log link is used in the gamma regression because the canonical inverse link  will cause some estimated marginal means to be extremely high and thus meaningless for intensity score.  

The linear predictor of the conditional intensity that includes video and relevant interactions is written in Equation \ref{eq:two-part1}.

\begin{align}\label{eq:two-part1}
E(I_{ijk} \mid I_{ijk} > 0) &= \mu + \alpha_i + \beta_j +\gamma_k + (\alpha\beta)_{ij} + (\alpha\gamma)_{ik} + (\beta\gamma)_{jk}
\end{align}

The model that captures additional speaker variable is written in Equation \ref{eq:two-part2}.  

\begin{align}\label{eq:two-part2}
E(I_{ijkl} \mid I_{ijkl} > 0) &= \mu + \alpha_i + \beta_j +\gamma_k + \delta_l + (\alpha\beta)_{ij} + (\alpha\gamma)_{ik} + (\beta\gamma)_{jk} + (\alpha\delta)_{il}
\end{align}


## Post-model analysis

The estimates of variables from the model summary are not particularly useful for our purpose. This is because firstly, the estimates of the coefficients are not interpretable in the logistic regression. Secondly, we are interested in *whether the mean for each treatment is same or different*? To assess which level of the factor is different requires post-model analysis.

### Estimated Marginal Mean (EMM)

The estimated marginal mean [@gelman2006data] is the fitted value from a model over the treatment effects. The treatment effects include judge, video and action unit in Model 2 and an additional speaker in Model 3. The estimated marginal mean is computed using `emmean()` from the `emmenas` package. The probability from estimated marginal mean can be interpreted as the estimated probability of presence (and intensity) score for a particular combination of action unit, judge and video. This output allows us to compare how the estimated presence (and intensity) are different or similar from each other. 


<!-- - good to know that: typically the tests and confidence intervals are asymptotic (because of using z score). Thus the df column for tabular results will be Inf.[have a look at the confidence interval for glm: https://cran.r-project.org/web/packages/emmeans/vignettes/models.html] -->


### Confidence Interval Adjustment

The confidence intervals computed from the `emmean()` function need to be adjusted for simultaneous inference. A 5% significance level indicates if we conduct 100 tests simultaneously, about 5 tests will show significance out of randomness. This is a problem we need to pay attention to when comparing the estimated presence probability or we may wrongly conclude judges has a different facial expression than others but they are actually not. 

When multiple estimated mean are compared at the same time, the confidence level need to be adjusted to control the family-wise error rate to be less than $\alpha$. Bonferroni adjustment makes the adjustment to reject a hypothesis test at $\alpha/N$ to control for the Family-wise Error Rate. `Confint()` function from base R is used with argument `adjust = "bonferroni"`.

\let\cleardoublepage\clearpage
