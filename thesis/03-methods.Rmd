---
chapter: 2
knit: "bookdown::render_book"
---

# Method

## Notation

Let $\mathbf{X}$ be a matrix of predictors, and $\mathbf{Y}$ variable in our case is bivariate matrix of response variables, including a binary indicator of presence/absence and a numeric value measuring intensity, of facial action unit, where 

- $X_1$ indicates `judge` with six categories $i = 1,2, \cdots, 6$

- $X_2$ indicates `video` for each of the seven cases, $j = 1,2, \cdots, 7$

- $X_3$ indicates action unit containing `r length(unique(au_tidy$AU))` possible facial expression.  

- $X_4$ indicates `speaker`, either the appellant or respondent, $l=1,2$

- $X_5$ indicates `frame` corresponding to time, $t = 1,2, \cdots, T_j$

Note that $t$ could be considered a time variable, but because images are taken at 1 minute intervals, temporal dependence is unlikely to exist. Rather this should be considered an independent observation. 

A full, main effects model for the data might be expressed as:

$$Y_{ijklt} = \mu + \alpha_i + \beta_j + \gamma_k + \delta_l + \varepsilon_{ijklt}$$ 

\noindent Also, let $P_{jitkl}$ represent the response variable presence, and $I_{jitkl}$ represent the response variable intensity. This notation will be helpful for defining the plots and models explained in this section.

## Modelling

### Model 1: Action unit

<!-- Interactions are included for judge and action unit -->


<!-- and we would be interested in interactions between judge, case, action unit and speaker. An alternative model structure, is to treat each action unit individually, and fit separate models.  -->

A binomial model with logistic link is first used to model the presence score. Interaction of judge and action unit is included to capture the judge-wise differences for different action units. The is necessary since from the exploratory data analysis, different judges  have different average presence score for different action units. The model can be written down as Equation \ref{eq:judge_au}. 

\begin{equation}\label{eq:judge_au}
P_{ik} = \mu + \alpha_i + \gamma_k + (\alpha\gamma)_{ik}
\end{equation}


### Model 2: Video

Build upon the first model, the second model adds the video related main effect and interactions, as shown in Equation \ref{eq:judge_video}. The interactions allow both judge and action unit variables to differ in different videos, which is useful to answer the research questions *whether the judges are behaving same or different across videos*. 

\begin{equation}\label{eq:judge_video}
P_{ijk} = \mu + \alpha_i + \beta_j +\gamma_k + (\alpha\beta)_{ij} + (\alpha\gamma)_{ik} + (\beta\gamma)_{jk}
\end{equation}

\noindent 

### Model 3: Speaker

Build upon the second model, the third model is aimed to capture the speaker-wise effect, that is, *do the expressions of the judges change when different parties are speaking*. The model formula is shown in Equation \ref{eq:judge_speaker}. 

\begin{equation}\label{eq:judge_speaker}
P_{ijkl} = \mu + \alpha_i + \beta_j +\gamma_k + \delta_l + (\alpha\beta)_{ij} + (\alpha\gamma)_{ik} + (\beta\gamma)_{jk} + (\alpha\delta)_{il}
\end{equation}

Interactions are still included in this model, but attention need to be paid to ensure the interactions are relevant. Theoretically, we could include speaker with all of the three existing variables (judge, action unit and video), but this would cause the model to run out of degree of freedom given the number of observations we have. Therefore, we only include judge-speaker interaction because it is directly related to the research question of this model. 


<!-- think about if it is necessary to adjust the standard error as well:  -->
<!-- if there are hetroskadasticity, the estimate itself is inconsistent, thus adjustment to make the standard error robust doesnt make sense.  -->

### Diagnostics 

<!-- not sure if I need a reference for ANOVA -->
<!-- @book{mcdonald2009handbook, -->
<!--   title={Handbook of biological statistics}, -->
<!--   author={McDonald, John H}, -->
<!--   volume={2}, -->
<!--   year={2009}, -->
<!--   publisher={sparky house publishing Baltimore, MD} -->
<!-- } -->

The analysis of variance (ANOVA) is a statistical method that compares the mean of each treatment level for a variable. Three types of ANOVA test are designed for different purposes. Type I takes a sequential approach to test the significance of variables, thus the order of the variable in the model will potentially affect the ANOVA result. Type II ANOVA tests the main effect of a covariate after controlling for other covariates but not interactions. This approach is recommended if the interactions are not significant. Type III ANOVA tests the main effect of a covariate after controlling for other covariates *and* the interactions. It is better than Type II ANOVA if the interactions are significant. 

Different packages in R conduct ANOVA test: `anova()` and `drop()` from base R provides type I and type II tests. `Anova()` from `car` package allows for both type II and III through specifying a `type` argument. `aov()` from `stats` package allows for ANOVA test only for balanced dataset. 

The ANOVA test provide variable significance, which allows us to understand if at least one treatment in the group is significantly different from others. This is useful before proceeds to the multiple comparison procedure, where we are able to talk which treatment(s) are different from others. 


## Post-Model Analysis


The estimates of variables from the model summary are not particularly useful in our case. This is because firstly,  the estimates of the coefficient are not interpretable in the logistic regression. Secondly, we are interested in whether the mean for each treatment is same or different. Thus estimated marginal mean and multiple comparison is necessary to compute for post-model analysis. 

### Estimated Marginal Mean (EMM)


The estimated marginal mean is the fitted value from a model over a pre-defined reference grid. In our data, the unique combination of judge, video and action unit forms the reference grid. The estimated marginal mean is computed on each grid point as a linear fit of the model, along with standard error and confidence interval. The probability from estimated marginal mean have a nice interpretation as the estimated probability of presence score for a particular combination of action unit, judge and video. This output allows us to compare how the estimated presence probabilities of each judge, video and action unit combination are different or similar from each other. 


<!-- - good to know that: typically the tests and confidence intervals are asymptotic (because of using z score). Thus the df column for tabular results will be Inf.[have a look at the confidence interval for glm: https://cran.r-project.org/web/packages/emmeans/vignettes/models.html] -->


### Multiple Comparisons 

Multiple comparison procedures consider the problem of simultaneous inference. A 5% significance level indicates if we conduct 100 tests simultaneously, about 5 tests will show significance out of randomness. This is a problem we need to pay attention to when comparing the estimated presence probability or we may wrongly conclude judges has a different facial expression than others but they are actually not. 


When multiple estimated mean are compared at the same time, the confidence level (or $\alpha$ in p-value) need to be adjusted to control the family-wise error rate to be less than $\alpha$. Bonferroni adjustment makes the adjustment to reject a hypothesis test at $\alpha/N$ level so that the type I error of whole family of the simultaneous tests (Family-wise Error Rate (FWER)) is control be less than $\alpha$. This can be proved using Boole's inequality if we denote the number of true $H_0$ as $N_0$.   

$$\Pr\left[\bigcup \Pr(P_i \le\frac{\alpha}{N})\right] \le \sum \Pr\left(p_i \le \frac{\alpha}{N}\right) = N_0\frac{\alpha}{N} \le \alpha$$

Testing significance based on p-value has been long criticised for its interpretation. Researchers can erroneously conclude significance because of p-value being less than 0.05 without discussing the false positive/negative proportion. On the other hand, confidence interval provides a confidence range for the estimates to highlight the uncertainty around estimation. Thus I will compute the confidence interval to compare whether the estimated mean for a particular judge-AU group is same or different across videos based on if the intervals overlap with each other. 




