---
title: "Exploration of Judicial Facial Expression in Videos of Legal Proceedings"
author: "Sherry Zhang" 
institution: "Monash University"
date: "`r Sys.Date()`"
output:
  xaringan::moon_reader:
    css: ["presdefault.css"]
    lib_dir: libs
    seal: FALSE
    nature:
      ratio: '4:3'
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
editor_options: 
  chunk_output_type: console
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      warning = FALSE, 
                      message = FALSE,
                      cache = TRUE, 
                      fig.path = "Figures/")

library(knitr)
library(ggplot2)
library(emmeans)
library(tidyverse)
load("../raw_data/au_tidy.rda")
load("../raw_data/au_meaning.rda")
```

class: title-slide, center, middle

# `r rmarkdown::metadata$title`

### `r rmarkdown::metadata$author` 

### [`r icon::fa_twitter()`](https:://twitter.com/huizezhangsh) huizezhangsh [`r icon::fa_github()`](https:://github.com/huizezhang-sherry) huizezhang-sherry

###`r rmarkdown::metadata$institution`

---

[![A video for fun](../images/video_photo.png)](https://www.youtube.com/watch?v=Ae7uKzin0GA)

### Are the justices facial expression revealing the outcome of the case?

---
# Recent legal studies on judicial behaviour

- Tutton et al. (2018): 

  - studied judicial demenaur
  
  - Facial expressions were recorded manually  
  
  - This observational approach 
  
  - subjective when different people are observing the same videos

This motivates me to study the facial expression of the judge via an more objective approach by using facial recognition technology. 


---
# Face Recognition


- **Paul Ekman**: Facial Action Coding System (FACS)


- **Action units**: fundamental units of human facial muscles. 


.pull-left[

AU02 -	Outer eyebrow raiser

```{r echo = FALSE, message = FALSE, warning = FALSE}
include_graphics("../images/AU2-right-only.gif")
```
]


.pull-right[

AU15 - Lip corner depressor

```{r echo = FALSE}
include_graphics("../images/AU15.gif")
```
]

 - widely used in facial recognition software development and human emotion reseraches

---

class: inverse, center, middle

# Video Processing

---

```{r echo = FALSE, fig.align="center", out.height="500px", out.width= "900px"}
include_graphics("../images/workflow_1 (0).png")
```

---

```{r echo = FALSE, fig.align="center", out.height="500px", out.width= "900px"}
include_graphics("../images/workflow_1 (1).png")
```

---

```{r echo = FALSE, fig.align="center", out.height="500px", out.width= "900px"}
include_graphics("../images/workflow_1 (2).png")
```

---

```{r echo = FALSE, fig.align="center", out.height="500px", out.width= "900px"}
include_graphics("../images/workflow_1 (3).png")
```

---

```{r echo = FALSE, fig.align="center", out.height="500px", out.width= "900px"}
include_graphics("../images/workflow_1 (4).png")
```

---

```{r echo = FALSE, fig.align="center", out.height="500px", out.width= "900px"}
include_graphics("../images/workflow_1 (5).png")
```

--

### 4601 faces and 711 facial variables!

---
class: middle, center


```{r echo = FALSE, warning=  FALSE}
include_graphics("../images/long.png")

```

---
class: inverse, center, middle

#  Method


---

## Notation: 

|Variable|Range|
|---|----|
|Judge| $i = 1,2, \cdots, 6$ |
|Video| $j = 1,2, \cdots, 7$ |
|Action unit|`r length(unique(au_tidy$AU))` possible facial expression|
|Speaker|either the appellant or respondent, $l=1,2$|
|Frame| $t = 1,2, \cdots, T_j$ |
|Presence |The binary $Y$ variable:  $P_{ijkl}$|


<!-- - $X_1$ indicates `judge` with six categories $i = 1,2, \cdots, 6$ -->
<!-- - $X_2$ indicates `video` for each of the seven cases, $j = 1,2, \cdots, 7$ -->
<!-- - $X_3$ indicates action unit containing `r length(unique(au_tidy$AU))` possible facial expression.   -->
<!-- - $X_4$ indicates `speaker`, either the appellant or respondent, $l=1,2$ -->
<!-- - $X_5$ indicates `frame` corresponding to time, $t = 1,2, \cdots, T_j$ -->
<!-- - $P_{ijkl}$ indicates the binary `presence` variable  -->

Main effects model: 

$$P_{ijkl} = \mu + \alpha_i + \beta_j + \gamma_k + \delta_l + \varepsilon_{ijkl}$$ 

---

## Modelling:

GLM model with binomial link: 

\begin{aligned}
P_{ijkl} &= \frac{e^{\eta_{ijkl}}}{1 + e^{\eta_{ijkl}}} \\
\eta_{ijkl} &= \mu + \alpha_i + \beta_j +\gamma_k + \delta_l + (\alpha\beta)_{ij} + (\alpha\gamma)_{ik} + (\beta\gamma)_{jk} + (\alpha\delta)_{il} + \varepsilon_{ijkl} \\
\end{aligned}


Do the Justices' expression differ

- from one case to another?

- when different parties were speaking? 

Method: 

- See if the confidence interval, after correcting for multiple comparison of the mean overlaps 

---
class: inverse, center, middle

#  Result

---

```{r video-plot, echo = FALSE, message = FALSE, warning = FALSE, fig.height=9, fig.width=12}
model_dt <- au_tidy %>% 
  ungroup(judge) %>% 
  mutate(judge = fct_relevel(judge, "Edelman"), 
         AU = fct_relevel(AU, "AU01")) 

model_dt_2 <- model_dt %>% 
  filter(AU %in% c("AU02", "AU14", "AU20","AU15")) 

binomial_model_2 <- glm(presence ~ judge*video + judge*AU + video*AU, 
                        family = binomial(link = "logit"),  
                        data = model_dt_2)

emmean_obj_2 <- emmeans(binomial_model_2, c("judge", "video", "AU"), 
                         type = "response") 

int_2 <- confint(emmean_obj_2, adjust = "bonferroni")

int_2 %>% 
  filter(!is.na(df)) %>% 
  mutate(judge = fct_relevel(judge, c("Edelman", "Keane", "Kiefel", "Nettle", "Gageler", "Bell"))) %>% 
  ggplot(aes(x= fct_relevel(video, c("Nauru-a", "Nauru-b", "Rinehart-a",
                               "Rinehart-b", "McKell", "OKS", "Parkes")), 
                            y = prob,  group = judge)) + 
  geom_point(aes(col= video)) + 
  geom_line(alpha = 0.5, lty = "dashed") + 
  geom_errorbar(aes(ymin = asymp.LCL, ymax = asymp.UCL, col= video), 
                width = 0.2) + 
  facet_grid(AU ~ judge, scales = "free") + 
  theme(axis.text.x = element_text(angle = 30, hjust = 1)) + 
  xlab("video")
```

---

```{r speaker-plot, echo = FALSE, message = FALSE, warning = FALSE, fig.height=9, fig.width=12}
model_dt_3 <- model_dt %>% 
  filter(AU %in% c("AU02", "AU14", "AU20","AU15")) 

binomial_model_3 <- glm(presence ~ judge*speaker + video*judge + AU*judge + video*AU, family = "binomial",  data = model_dt_3)

emmean_obj_3 <-  emmeans(binomial_model_3, 
                         c("judge", "video", "AU", "speaker") , 
                         type = "response")
int_3 <- confint(emmean_obj_3,  adjust = "bonferroni")

int_3 %>% 
  filter(!is.na(df)) %>% 
  ggplot(aes(x= fct_relevel(video, c("Nauru-a", "Nauru-b", "Rinehart-a",
                               "Rinehart-b", "McKell", "OKS", "Parkes")), 
             y = prob, col = speaker)) + 
  geom_point() + 
  geom_errorbar(aes(ymin = asymp.LCL, ymax = asymp.UCL), width = 0.2) + 
  facet_grid(AU ~ fct_relevel(judge, c("Edelman", "Keane", "Kiefel", "Nettle", "Gageler", "Bell")), scales = "free_x") + 
  theme(axis.text.x = element_text(angle = 30, hjust = 1)) + 
  xlab("video")
```


---
class: center, middle

# Acknowledgement

I would like to express my gratitude to Di Cook and Russell Symth for supervising, Stephanie Kobakian and Stuart Lee for helping me throughout the project.

Slides created via the R package [**xaringan**](https://github.com/yihui/xaringan).


