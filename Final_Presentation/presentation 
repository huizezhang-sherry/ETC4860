Hi Everyone, Today I will be talking about exploring the judicial facial expression in videos of legal proceedings. You can go to this link to follow my talk. 

---

# Background

The videos of legal proceedings are available from the High Court of Australia, and here is a sample from The republic of Nauru v WET040.

[play video]

---

The Justices are expected to appear impartial in the courtroom. However, can you keep a straight face? Its hard not to react emotionally sometimes. 

There have been many studies into facial and vocal expressions of judges, based on court transcripts, or empirical studies. 

Chen published a paper in 2018 named Is Justice really blind? And it is also deaf. He processed the images of the attorneys before appearing on the US Supreme Court. Audio information is also included in Chen's data to classify if the supreme court judge would affirm or reverse a low court decision. Chen found that both the image and audio data improve the classification accuracy of case outcome. 

-- 

In Australia, Tutton et al used the transcripts and AV recordings of judges during the hearing to study the emotion of the judges in the High Court of Australia. They found that the judges behaved with a detached demeanour. Their video analysis was done with manual annotation. 

--

My work is partly motivated by Kovalchik and Reid's 2018 study of facial expressions of tennis players and whether their performance is affected by their emotions in the Australian Open matches. 

---

My research studies the Justices from the High Court of Australia, using AV recordings. 

I have extracted the faces of the justices from the videos, and examine the facial expressions. I have analysed the text transcript of the hearing to get the information about who is speaking. I then statistically model the judges facial expression using the data I processed to oebjectively study the emtion of the Justices. I want to find out, do my result agree or disagree with Tutton's findings, that the justices are appearing impartial. 

---

## Face recognition 

Facial recognition technology is based on an action unit coding System by Paul Ekman. It groups movements of facial landmarks into 45 action units. 
Here is an explanation of two action units.

Action unit 2 is the raising of outer eyebrow. This might be associated with surprise. 

Action unit 15 is the lip corner depressor. This might be associated with disgust.

---

## Data collection

This flowchart outlines the steps I have taken to collect the data.

The videos are first downloaded from the high Court of Australia website, and chopped into a set of images extracted at 1 minute intervals. This produces 1000 frames. The face recognition is conducted on these still images. 

Faces are extracted from each image. Because the Justices are remain seated in the same position through out the hearing, their faces can be easily extracted by cropping a fixed region of the image. This yields 4600 images total. 

The images are all processed with the face recognition software which tags each face with the facial action unit presence and intensity, along with many other variables like landmarks and eye focus. 

The information is collected into one csv file that contains 711 facial variables. 

One additional step is to analyse the transcript to extract times when the appellant and respondent were addressing the judges. 

---

The collected dataset contains 7 videos of 6 judges and 18 action units. Other facial variables obtained includes the coordinates of 68 face landmarks and 56 eye landmarks. In total, I processed 1000 image frames and 4600 faces. 
---

The final data format looks like this. We have judge_id, video_id, frame_id for each face. Speakers (appellant or respondent) is extracted from the text trascript. There are 18 action units and presence/absence of the action unit, and intensity score for the action unit.  

---

## Method

To be able to model the facial expression of the judge, the following notations are defined. $i$ is the subscript for judge and can take value from 1 to 6 for our 6 different judges. Video is represented by $j$ subscript and have 7 distinct values. Action unit is represented by $k$, speakers is subsripted by $l$. There is also a time variable indicating the 1 minute interval. 

The response variable used for this model is the binary presence variable, indicating whether the action unit is observed or not. 

---

## Modelling

The judges facial expressions are modelled using a binomial model with logit link, because the response variable is binary. 

alpha_i, beta_j, gamma_k and delta_l represent the main effect of judge, video, action unit and speaker, respectively.

The interaction term between judge (alpha) and video (beta_j) allows different judges to react differently in different videos. Similarly we have interactions between judge and action unit, judge and speaker, and action unit and speaker. [Maybe more explanation on the interaction terms??] 

--

With the model, we are able to answer the following two questions: Do the  expression of the justices differ from case to case and Do the expression of the justices differ when different parties are speaking. 

---

# Result 

These are the first 10 rows of the model summary output. It is difficult to interpret the model based on this output. There are many parameters, and we are more interested in how the treatment means are different, or similar. 


---

## ANOVA

The ANOVA summary says that the judge, video and AU are all significant, but it doesn't specifically tell us which means are different from each other.  Therefore, I apply multiple comparison to adjust the confidence interval. 

---

## Bonferroni 

In multiple comparison, the adjustment to confidence interval is made to ensure the confidence level of the whole group is 95%. In my context, it is to ensure the judge-wise confidence is 95%. To do this, I use Bonferroni adjustment. [Do I need to further explain how does bonferroni adjustment do this??? Maybe put as an appendix slide?? Just in the appendix]

---

This plot is a summary of the multiple comparisons. It shows the 95% confidence intervals, for the model estimates. 

The x axis represents video and y axis represents the proportion of frames in each video where the action unit was present. The facets show judge in the columns, and four main action units on the rows. Colour represents video. 

Note that, each case may have different judges.

Here are the main observations we can make from this plot. 

The facial expressions of Judge Edelman, Keane and Kiefel were relatively consistent throughout all the videos they participated. 

Judge Gageler reacted differently in the OKS case, on the four main action units. 

In the same OKS case, Judge Bell also shows each expression with a higher proportion. 

---

## Summary of results

Our results mostly validate Tutton et al (2018) that the judges appear impartial, with the exception of Gageler and Bell for the OKS case.

An important emphasis of this work is that "Facial recognition analysis of the videos provides a way to objectively assess judicial behaviour."

---

# Future work

To finalise this work, I will also model the intensity score of the action units. Here is a histogram of the intensity by judge. Most of the intensity score is near zero. So a zero inflated model would be able to handle this. 

---

# Caveats

There are a few cautions about this work. 

The current image frames are extracted at every 1 minute interval. However, we would expect some facial expression may only last for a few second, so we could sample more frequently. 

I processed 7 videos into the facial recognition software and there are more videos which could be added. Some of the other videos were not used because the faces were too small to be recognised.

However, I have mostly scripted the pre-processing to the data, and this is available from my github repo. If a re-processing, or more videos are added, it is straightforward for others to do.


---

## Packages used in the research include

This is the list of software and R packages used for this work.

[Spell out what software is used for what purpose, briefly]

# Acknowledgement

Thank you for listening


